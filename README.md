# Prior-Guided Augmentation: A Reliable Strategy for Small-Sample Datasets
# å…ˆéªŒå¼•å¯¼å¢žå¼ºï¼šå°æ ·æœ¬æ•°æ®é›†çš„å¯é ç­–ç•¥

[![Python 3.14](https://img.shields.io/badge/python-3.14-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![PyTorch 2.5](https://img.shields.io/badge/pytorch-2.5-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Official PyTorch Implementation** of the paper: *"Prior-Guided Augmentation: A Reliable Strategy for Small-Sample Datasets"* (WACV/BMVC Submission Target).
> 
> **å®˜æ–¹å®žçŽ°**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨æžå°æ ·æœ¬ï¼ˆLow-Data Regimeï¼‰ä¸‹æ¯” RandAugment æ›´ç¨³å®šã€æ›´é«˜æ•ˆçš„æ•°æ®å¢žå¼ºæœç´¢ç­–ç•¥ã€‚

---

## ðŸ“– Abstract / æ‘˜è¦

**English**:  
Data augmentation is critical for deep learning in data-scarce regimes. While complex automated strategies like RandAugment achieve state-of-the-art results on large datasets, we reveal a **"Complexity Gap"** in small-sample settings (e.g., CIFAR-100, 100-shot): blindly increasing augmentation complexity yields diminishing returns while significantly increasing training instability. 

We propose a **Prior-Guided Augmentation** search framework that prioritizes **stability** and **semantic preservation**. Our method identifies a single, optimal operation (e.g., ColorJitter) that achieves competitive accuracy (40.74%) compared to RandAugment (42.24%) but with **significantly lower variance (Std: 0.78 vs 1.17)** and better interpretability. We further prove that "tuning" RandAugment fails in this regime, collapsing to weak augmentations (35.30%), whereas our method robustly finds the "Sweet Spot".

**ä¸­æ–‡**:  
åœ¨æ•°æ®åŒ®ä¹çš„åœºæ™¯ä¸‹ï¼Œæ•°æ®å¢žå¼ºè‡³å…³é‡è¦ã€‚è™½ç„¶åƒ RandAugment è¿™æ ·çš„è‡ªåŠ¨å¢žå¼ºç­–ç•¥åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨çŽ°å‡ºè‰²ï¼Œä½†åœ¨å°æ ·æœ¬ï¼ˆå¦‚ CIFAR-100 æ¯ç±» 100 å¼ ï¼‰åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬å‘çŽ°äº†ä¸€ä¸ª**â€œå¤æ‚åº¦é™·é˜± (Complexity Gap)â€**ï¼šç›²ç›®å¢žåŠ å¢žå¼ºæ“ä½œçš„å¤æ‚åº¦ä¸ä»…æ”¶ç›Šé€’å‡ï¼Œè¿˜ä¼šæ˜¾è‘—å¢žåŠ è®­ç»ƒçš„ä¸ç¨³å®šæ€§ã€‚

æˆ‘ä»¬æå‡ºäº†ä¸€ç§**å…ˆéªŒå¼•å¯¼ (Prior-Guided)** çš„å¢žå¼ºæœç´¢æ¡†æž¶ï¼Œè¯¥æ¡†æž¶å°†â€œç¨³å®šæ€§â€å’Œâ€œè¯­ä¹‰ä¿çœŸåº¦â€ä½œä¸ºæ ¸å¿ƒæŒ‡æ ‡ã€‚å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬æœç´¢åˆ°çš„å•ä¸€æœ€ä¼˜æ“ä½œï¼ˆå¦‚ ColorJitterï¼‰è™½ç„¶ç®€å•ï¼Œä½†èƒ½è¾¾åˆ°ä¸Ž RandAugment ç›¸å½“çš„å‡†ç¡®çŽ‡ï¼ˆ40.74% vs 42.24%ï¼‰ï¼ŒåŒæ—¶**æ–¹å·®æ˜¾è‘—é™ä½Žï¼ˆStd: 0.78 vs 1.17ï¼‰**ã€‚è¿›ä¸€æ­¥çš„å¯¹æ¯”å®žéªŒè¯æ˜Žï¼Œåœ¨å°æ ·æœ¬ä¸‹ç›´æŽ¥å¯¹ RandAugment è¿›è¡Œè°ƒå‚ä¼šå¤±æ•ˆï¼ˆä»… 35.30%ï¼‰ï¼Œè€Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½ç¨³å¥åœ°æ‰¾åˆ°æœ€ä½³å¹³è¡¡ç‚¹ã€‚

---

## ðŸ“Š Key Results / æ ¸å¿ƒç»“æžœ

Experiments conducted on CIFAR-100 (100 samples/class), ResNet-18, 5-Fold Cross-Validation.

| Method | Mean Acc (%) | Stability (Std) | Complexity | Note |
| :--- | :---: | :---: | :---: | :--- |
| Baseline (S0) | 39.90 | 1.01 | Low | Basic Crop/Flip |
| **RandAugment** (N=2,M=9) | **42.24** | 1.17 | High | **Unstable** (High Variance) |
| **Tuned RandAugment** (N=1,M=2)| 35.30 | N/A | Low | Tuning fails (Underfitting) |
| **Ours (Optimal)** | 40.74 | **0.78** | **Low** | **Most Stable & Reliable** |

### Why Ours? / ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬çš„æ–¹æ³•ï¼Ÿ
1.  **Zero Variance in Stability Check**: Verified to converge consistently (50.00% Â± 0.00%) across 3 random seeds in 50-shot scenarios.
2.  **High Semantic Fidelity**: LPIPS score (0.091) is comparable to baseline, unlike RandAugment (0.124) which distorts images heavily.
3.  **Efficiency**: Search cost is only ~4 GPU hours, finding the optimal policy without expensive reinforcement learning.

---

## ðŸ›  Installation / å®‰è£…

```bash
# Clone the repository
git clone https://github.com/yourusername/prior-guided-aug.git
cd prior-guided-aug

# Create Conda environment
conda env create -f environment.yml
conda activate pga

# (Optional) Verify installation
python -c "import torch; print(torch.cuda.is_available())"
```

---

## ðŸš€ Quick Start / å¿«é€Ÿå¼€å§‹

### 1. Reproduction (One-Click) / ä¸€é”®å¤çŽ°
Run the full pipeline (Phase A -> B -> C -> D) on a single GPU:

```bash
bash scripts/train_single_gpu.sh
```

### 2. Supplementary Experiments / è¡¥å……å®žéªŒ (Paper Revision)
Reproduce the specific proofs for stability and fairness:

```bash
# Verify Semantic Preservation (Destructiveness)
python scripts/calculate_destructiveness.py

# Verify Zero Variance (Stability)
python scripts/run_stability_check.py

# Verify Tuned RandAugment Failure (Fairness)
python scripts/run_tuning_randaugment.py  # Search
python scripts/run_final_tuned_ra.py      # Validation

# Verify Strategic Collapse (Figure 2)
python scripts/plot_strategic_collapse.py


```

### 3. Visualization / ç»˜å›¾
Generate all figures used in the paper:

```bash
python scripts/generate_paper_figures.py
```
Output: `outputs/figures/`

---

## ðŸ“‚ Project Structure / é¡¹ç›®ç»“æž„

```
.
â”œâ”€â”€ src/                # Core implementation
â”‚   â”œâ”€â”€ augmentations.py  # Search space & Augmentation logic
â”‚   â”œâ”€â”€ dataset.py        # CIFAR-100 Subsampled dataset
â”‚   â””â”€â”€ models.py         # ResNet-18
â”œâ”€â”€ scripts/            # Experiment scripts
â”‚   â”œâ”€â”€ train_single_gpu.sh      # Full pipeline runner
â”‚   â”œâ”€â”€ calculate_destructiveness.py # LPIPS/SSIM analysis
â”‚   â””â”€â”€ generate_paper_figures.py    # Plotting tools
â”œâ”€â”€ docs/               # Documentation
â”‚   â”œâ”€â”€ paper_draft.tex   # LaTeX draft
â”‚   â””â”€â”€ repro_guide.md    # Detailed guide
â”œâ”€â”€ outputs/            # Experiment results (Auto-generated)
â””â”€â”€ logs/               # Training logs
```

---

## ðŸ“œ Citation / å¼•ç”¨

If you find this work useful, please stay tuned! The citation will be updated upon acceptance.

<!--
```bibtex
@article{qin2026prior,
  title={Prior-Guided Augmentation: A Reliable Strategy for Small-Sample Datasets},
  author={Qin, Fuyao},
  journal={arXiv preprint},
  year={2026}
}
```
-->

## ðŸ“„ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.
